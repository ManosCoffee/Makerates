id: rates_daily2
namespace: makerates

description: |
  Daily Currency Rates Pipeline - Persistent Volume Architecture

  Runs once per day to:
  1. Check API quotas
  2. Extract from Frankfurter/ExchangeRate-API
  3. Transform with dbt (writes to persistent /data/analytics.duckdb)
  4. Upsert validated rates to DynamoDB (reads from persistent /data/analytics.duckdb)

labels:
  project: makerates
  type: incremental
  env: production

inputs:
  - id: execution_date
    type: DATE
    defaults: "{{ trigger.date ?? now() | date('yyyy-MM-dd') }}"
  - id: include_currencylayer
    type: BOOLEAN
    defaults: false
    description: "Run optional 3rd source (CurrencyLayer) - Consumes Quota!"

variables:
  run_mode: "daily"
  # MinIO
  minio_endpoint: "{{ envs.minio_endpoint }}"
  minio_root_user: "{{ envs.minio_root_user }}"
  minio_root_password: "{{ envs.minio_root_password }}"
  # DLT
  dlt_bucket_url: "{{ envs.destination__filesystem__bucket_url }}"
  dlt_layout: "{{ envs.destination__filesystem__layout }}"
  dlt_aws_access_key_id: "{{ envs.destination__filesystem__credentials__aws_access_key_id }}"
  dlt_aws_secret_access_key: "{{ envs.destination__filesystem__credentials__aws_secret_access_key }}"
  # DynamoDB
  dynamodb_endpoint: "{{ envs.dynamodb_endpoint }}"
  ddb_access_key_id: "{{ envs.dynamodb_aws_access_key_id }}"
  ddb_secret_access_key: "{{ envs.dynamodb_aws_secret_access_key }}"
  ddb_default_region: "{{ envs.dynamodb_aws_default_region }}"
  dynamodb_currencies_table_name: "{{ envs.dynamodb_currencies_table_name }}"
  # API Keys
  currencylayer_api_key: "{{ envs.currencylayer_api_key }}"
  exchangerate_api_key: "{{ envs.exchangerate_api_key }}"
  # Buckets
  source_bucket: "s3://{{ envs.bronze_bucket }}"
  target_bucket: "s3://{{ envs.silver_bucket }}/iceberg"  
  # Iceberg
  pyiceberg_catalog_default_uri : "{{envs.pyiceberg_catalog_default_uri}}"
  pyiceberg_catalog_default_type : "{{envs.pyiceberg_catalog_default_type}}"
  pyiceberg_catalog_default_warehouse: "s3://{{ envs.silver_bucket }}/iceberg"
  iceberg_catalog: "{{envs.iceberg_catalog}}"
  iceberg_namespace: "{{envs.iceberg_namespace}}"
  # Source Prefixes
  frankfurter_source_prefix: "{{envs.frankfurter_source_prefix}}"
  currencylayer_source_prefix: "{{envs.currencylayer_source_prefix}}"
  exchangerate_source_prefix: "{{envs.exchangerate_source_prefix}}"
  frankfurter_table_name: "{{envs.frankfurter_table_name}}"
  currencylayer_table_name: "{{envs.currencylayer_table_name }}"
  exchangerate_table_name: "{{envs.exchangerate_table_name}}"
  # DBT
  dbt_silver_bucket: "s3://{{ envs.silver_bucket }}"
  dbt_iceberg_base_path: "iceberg"

tasks:
  # ===== 1. QUOTA CHECK =====
  - id: check_quotas
    type: io.kestra.plugin.docker.Run
    containerImage: makerates-ingestion-base:latest
    pullPolicy: NEVER
    networkMode: makerates-network
    env:
      DYNAMODB_ENDPOINT: "{{ vars.dynamodb_endpoint }}"
      DYNAMODB_AWS_ACCESS_KEY_ID: "{{ vars.ddb_access_key_id }}"
      DYNAMODB_AWS_SECRET_ACCESS_KEY: "{{ vars.ddb_secret_access_key }}"
      DYNAMODB_AWS_DEFAULT_REGION: "{{ vars.ddb_default_region }}"
    commands:
      - quotas_endpoint

  # ===== 2. EXTRACT =====
  - id: extract_parallel
    type: io.kestra.plugin.core.flow.Parallel
    tasks:
      - id: extract_frankfurter
        type: io.kestra.plugin.docker.Run
        containerImage: makerates-ingestion-base:latest
        pullPolicy: NEVER
        networkMode: makerates-network
        runIf: '{{ true }}' 
        env:
          AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
          AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
          AWS_DEFAULT_REGION: "{{ vars.ddb_default_region }}"
          DYNAMODB_ENDPOINT: "{{ vars.dynamodb_endpoint }}"
          DYNAMODB_AWS_ACCESS_KEY_ID: "{{ vars.ddb_access_key_id }}"
          DYNAMODB_AWS_SECRET_ACCESS_KEY: "{{ vars.ddb_secret_access_key }}"
          MINIO_ENDPOINT: "{{ vars.minio_endpoint }}"
          AWS_ENDPOINT_URL: "{{ vars.minio_endpoint }}"
          DESTINATION__FILESYSTEM__BUCKET_URL: "{{ vars.dlt_bucket_url }}"
          DESTINATION__FILESYSTEM__LAYOUT: "{{ vars.dlt_layout }}"
          DESTINATION__FILESYSTEM__EXTRA_PLACEHOLDERS: '{"run_mode": "daily"}'
          DESTINATION__FILESYSTEM__KWARGS__CLIENT_KWARGS__ENDPOINT_URL: "{{ vars.minio_endpoint }}"
          DESTINATION__FILESYSTEM__CREDENTIALS__AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
          DESTINATION__FILESYSTEM__CREDENTIALS__AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
        commands:
          - frankfurter_extractor
        timeout: PT5M
        allowFailure: true

      - id: extract_exchangerate
        type: io.kestra.plugin.docker.Run
        containerImage: makerates-ingestion-base:latest
        pullPolicy: NEVER
        networkMode: makerates-network
        runIf: '{{ outputs.check_quotas.vars.exchangerate }}'
        env:
          AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
          AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
          AWS_DEFAULT_REGION: "{{ vars.ddb_default_region }}"
          DYNAMODB_ENDPOINT: "{{ vars.dynamodb_endpoint }}"
          DYNAMODB_AWS_ACCESS_KEY_ID: "{{ vars.ddb_access_key_id }}"
          DYNAMODB_AWS_SECRET_ACCESS_KEY: "{{ vars.ddb_secret_access_key }}"
          AWS_ENDPOINT_URL: "{{ vars.minio_endpoint }}"
          DESTINATION__FILESYSTEM__BUCKET_URL: "{{ vars.dlt_bucket_url }}"
          DESTINATION__FILESYSTEM__LAYOUT: "{{ vars.dlt_layout }}"
          DESTINATION__FILESYSTEM__EXTRA_PLACEHOLDERS: '{"run_mode": "daily"}'
          DESTINATION__FILESYSTEM__KWARGS__CLIENT_KWARGS__ENDPOINT_URL: "{{ vars.minio_endpoint }}"
          DESTINATION__FILESYSTEM__CREDENTIALS__AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
          DESTINATION__FILESYSTEM__CREDENTIALS__AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
        commands:
          - exchangerate_extractor
        timeout: PT5M
        allowFailure: true
      
      - id: extract_currencylayer
        type: io.kestra.plugin.docker.Run
        containerImage: makerates-ingestion-base:latest
        pullPolicy: NEVER
        networkMode: makerates-network
        runIf: '{{ inputs.include_currencylayer or (not outputs.check_quotas.vars.exchangerate) }}'
        env:
          CURRENCYLAYER_API_KEY: "{{ envs.currencylayer_api_key }}"
          AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
          AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
          MINIO_ENDPOINT: "{{ vars.minio_endpoint }}"
          AWS_ENDPOINT_URL: "{{ vars.minio_endpoint }}"
          DESTINATION__FILESYSTEM__BUCKET_URL: "{{ vars.dlt_bucket_url }}"
          DESTINATION__FILESYSTEM__LAYOUT: "{{ vars.dlt_layout }}"
          DESTINATION__FILESYSTEM__EXTRA_PLACEHOLDERS: '{"run_mode": "daily"}'
          DESTINATION__FILESYSTEM__KWARGS__CLIENT_KWARGS__ENDPOINT_URL: "{{ vars.minio_endpoint }}"
          DESTINATION__FILESYSTEM__CREDENTIALS__AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
          DESTINATION__FILESYSTEM__CREDENTIALS__AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
          DYNAMODB_ENDPOINT: "{{ vars.dynamodb_endpoint }}"
          DYNAMODB_AWS_ACCESS_KEY_ID: "{{ vars.ddb_access_key_id }}"
          DYNAMODB_AWS_SECRET_ACCESS_KEY: "{{ vars.ddb_secret_access_key }}"
        commands:
          - currencylayer_extractor
        timeout: PT5M
        allowFailure: true

  # ===== 2a. INITIALIZE ICEBERG CATALOG =====
  - id: init_iceberg_catalog
    type: io.kestra.plugin.docker.Run
    containerImage: makerates-ingestion-base:latest
    pullPolicy: NEVER
    networkMode: makerates-network
    env:
      PYICEBERG_CATALOG__DEFAULT__TYPE: "{{ vars.pyiceberg_catalog_default_type }}"
      PYICEBERG_CATALOG__DEFAULT__URI: "{{ vars.pyiceberg_catalog_default_uri }}"
      PYICEBERG_CATALOG__DEFAULT__S3__ENDPOINT: "{{ vars.minio_endpoint }}"
      PYICEBERG_CATALOG__DEFAULT__WAREHOUSE: "{{ vars.pyiceberg_catalog_default_warehouse }}"
      AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
      AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
      AWS_ENDPOINT_URL: "{{ vars.minio_endpoint }}"
      ICEBERG_CATALOG: "{{ vars.iceberg_catalog }}"
      ICEBERG_NAMESPACE: "{{ vars.iceberg_namespace }}"
    commands:
      - init_iceberg_catalog

  # ===== 2b. COMPACT TO ICEBERG =====
  - id: create_iceberg_sources
    type: io.kestra.plugin.core.flow.Parallel
    tasks:
      - id: load_frankfurter_to_iceberg
        dependsOn:
          - extract_frankfurter
        type: io.kestra.plugin.docker.Run
        containerImage: makerates-ingestion-base:latest
        pullPolicy: NEVER
        networkMode: makerates-network
        env:
          # AWS creds fro MinIO S3 (ICEBERG)
          AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
          AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
          AWS_REGION: "{{ vars.ddb_default_region }}"
          AWS_ENDPOINT_URL: "{{ vars.minio_endpoint }}"
          # AWS creds for DynamoDB (ICEBERG)
          DYNAMODB_ENDPOINT: "{{ vars.dynamodb_endpoint }}"
          DYNAMODB_AWS_ACCESS_KEY_ID: "{{ vars.ddb_access_key_id }}"
          DYNAMODB_AWS_SECRET_ACCESS_KEY: "{{ vars.ddb_secret_access_key }}"
          # BUCKETS & ICEBERG CONFIGS
          SOURCE_BUCKET: "{{ vars.source_bucket }}"
          SOURCE_PREFIX: "{{ vars.frankfurter_source_prefix }}"
          TARGET_BUCKET: "{{ vars.target_bucket }}"
          TABLE_NAME: "{{ vars.frankfurter_table_name }}"
          ICEBERG_CATALOG: "{{ vars.iceberg_catalog }}"
          ICEBERG_NAMESPACE: "{{ vars.iceberg_namespace }}"
          PYICEBERG_CATALOG__DEFAULT__TYPE: "{{ vars.pyiceberg_catalog_default_type }}"
          PYICEBERG_CATALOG__DEFAULT__URI: "{{ vars.pyiceberg_catalog_default_uri }}"
          PYICEBERG_CATALOG__DEFAULT__S3__ENDPOINT: "{{ vars.minio_endpoint }}"
          PYICEBERG_CATALOG__DEFAULT__WAREHOUSE: "{{ vars.pyiceberg_catalog_default_warehouse }}"
        commands:
          - iceberg_loader 
          - "--start-date={{ inputs.execution_date }}"
          - "--mode={{ vars.run_mode }}"

      - id: load_exchangerate_to_iceberg
        dependsOn:
          - extract_exchangerate
        type: io.kestra.plugin.docker.Run
        containerImage: makerates-ingestion-base:latest
        pullPolicy: NEVER
        networkMode: makerates-network
        runIf: '{{ outputs.check_quotas.vars.exchangerate }}'
        env:
          # AWS creds fro MinIO S3 (ICEBERG)
          AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
          AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
          AWS_REGION: "{{ vars.ddb_default_region }}"
          AWS_ENDPOINT_URL: "{{ vars.minio_endpoint }}"
          # AWS creds for DynamoDB (ICEBERG)
          DYNAMODB_ENDPOINT: "{{ vars.dynamodb_endpoint }}"
          DYNAMODB_AWS_ACCESS_KEY_ID: "{{ vars.ddb_access_key_id }}"
          DYNAMODB_AWS_SECRET_ACCESS_KEY: "{{ vars.ddb_secret_access_key }}"
          # BUCKETS & ICEBERG CONFIGS
          SOURCE_BUCKET: "{{ vars.source_bucket }}"
          SOURCE_PREFIX: "{{ vars.exchangerate_source_prefix }}"
          TARGET_BUCKET: "{{ vars.pyiceberg_catalog_default_warehouse }}"
          TABLE_NAME: "{{ vars.exchangerate_table_name }}"
          ICEBERG_CATALOG: "{{ vars.iceberg_catalog }}"
          ICEBERG_NAMESPACE: "{{ vars.iceberg_namespace }}"
          PYICEBERG_CATALOG__DEFAULT__TYPE: "{{vars.pyiceberg_catalog_default_type}}"
          PYICEBERG_CATALOG__DEFAULT__URI: "{{vars.pyiceberg_catalog_default_uri}}"
          PYICEBERG_CATALOG__DEFAULT__S3__ENDPOINT: "{{ vars.minio_endpoint }}"
          PYICEBERG_CATALOG__DEFAULT__WAREHOUSE: "{{ vars.pyiceberg_catalog_default_warehouse }}"
        commands:
          - iceberg_loader 
          - "--start-date={{ inputs.execution_date }}"
          - "--mode={{ vars.run_mode }}"
      
      - id: load_currencylayer_to_iceberg
        dependsOn:
          - extract_currencylayer
        type: io.kestra.plugin.docker.Run
        containerImage: makerates-ingestion-base:latest
        pullPolicy: NEVER
        networkMode: makerates-network
        runIf: '{{ inputs.include_currencylayer or (not outputs.check_quotas.vars.exchangerate) }}'
        env:
          # AWS creds fro MinIO S3 (ICEBERG)
          AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
          AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
          AWS_REGION: "{{ vars.ddb_default_region }}"
          AWS_ENDPOINT_URL: "{{ vars.minio_endpoint }}"
          # AWS creds for DynamoDB (ICEBERG)
          DYNAMODB_ENDPOINT: "{{ vars.dynamodb_endpoint }}"
          DYNAMODB_AWS_ACCESS_KEY_ID: "{{ vars.ddb_access_key_id }}"
          DYNAMODB_AWS_SECRET_ACCESS_KEY: "{{ vars.ddb_secret_access_key }}"
          # BUCKETS & ICEBERG CONFIGS
          SOURCE_BUCKET: "{{ vars.source_bucket }}"
          SOURCE_PREFIX: "{{ vars.currencylayer_source_prefix }}"
          TARGET_BUCKET: "{{ vars.pyiceberg_catalog_default_warehouse }}"
          TABLE_NAME: "{{ vars.currencylayer_table_name }}"
          ICEBERG_CATALOG: "{{ vars.iceberg_catalog }}"
          ICEBERG_NAMESPACE: "{{ vars.iceberg_namespace }}"
          PYICEBERG_CATALOG__DEFAULT__TYPE: "{{vars.pyiceberg_catalog_default_type}}"
          PYICEBERG_CATALOG__DEFAULT__URI: "{{vars.pyiceberg_catalog_default_uri}}"
          PYICEBERG_CATALOG__DEFAULT__S3__ENDPOINT: "{{ vars.minio_endpoint }}"
          PYICEBERG_CATALOG__DEFAULT__WAREHOUSE: "{{ vars.pyiceberg_catalog_default_warehouse }}"
        commands: 
          - iceberg_loader 
          - "--start-date={{ inputs.execution_date }}"
          - "--mode={{ vars.run_mode }}"

  # ===== 2c. FETCH METADATA LOCATIONS FROM DYNAMODB =====
  - id: fetch_iceberg_metadata_paths
    type: io.kestra.plugin.scripts.python.Script
    containerImage: python:3.12-slim
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      networkMode: makerates-network
    dependsOn:
      - create_iceberg_sources
    beforeCommands:
      - pip install boto3 kestra
    env:
      AWS_ACCESS_KEY_ID: "{{ vars.ddb_access_key_id }}"
      AWS_SECRET_ACCESS_KEY: "{{ vars.ddb_secret_access_key }}"
      AWS_DEFAULT_REGION: "{{ vars.ddb_default_region }}"
      DYNAMODB_ENDPOINT: "{{ vars.dynamodb_endpoint }}"
    script: |
      import boto3
      import os
      from kestra import Kestra

      # Initialize DynamoDB client
      ddb = boto3.client(
          'dynamodb',
          endpoint_url=os.environ['DYNAMODB_ENDPOINT'],
          region_name=os.environ['AWS_DEFAULT_REGION'],
          aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],
          aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY']
      )

      # Fetch metadata for each table
      tables = {
          'frankfurter_rates': 'frankfurter_metadata',
          'exchangerate_rates': 'exchangerate_metadata',
          'currencylayer_rates': 'currencylayer_metadata'
      }

      outputs = {}
      for table_name, output_key in tables.items():
          try:
              response = ddb.get_item(
                  TableName='iceberg_metadata',
                  Key={'table_name': {'S': table_name}}
              )
              if 'Item' in response and 'metadata_location' in response['Item']:
                  metadata_location = response['Item']['metadata_location']['S']
                  outputs[output_key] = metadata_location
                  print(f"✅ {table_name}: {metadata_location}")
              else:
                  outputs[output_key] = ""
                  print(f"⚠️  {table_name}: No metadata found")
          except Exception as e:
              outputs[output_key] = ""
              print(f"❌ {table_name}: Error - {e}")

      # Output using Kestra SDK 
      Kestra.outputs(outputs)

  # ===== 3. TRANSFORM (dbt) =====
  - id: git_sync
    type: io.kestra.plugin.git.SyncNamespaceFiles
    url: https://github.com/ManosCoffee/Makerates
    branch: main
    namespace: makerates
    gitDirectory: dbt_project
    
  - id: dbt_validation_and_transform
    type: io.kestra.plugin.dbt.cli.DbtCLI
    containerImage: makerates-ingestion-base:latest
    allowWarning: true
    dependsOn:
      - fetch_iceberg_metadata_paths
    namespaceFiles:
      enabled: true
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      networkMode: makerates-network
      # volumes
        # - /Users/manos/dev/makerates/data:/data
    outputFiles:
      - analytics.duckdb
    env:
      AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
      AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
      AWS_ENDPOINT_URL: "{{ vars.minio_endpoint }}"
      AWS_REGION: "{{ vars.ddb_default_region }}"
      MINIO_ENDPOINT: "{{ vars.minio_endpoint }}"
      MINIO_ROOT_USER: "{{ vars.minio_root_user }}"
      MINIO_ROOT_PASSWORD: "{{ vars.minio_root_password }}"
      DUCKDB_PATH: "analytics.duckdb" # Writes to working dir for outputFiles
      DBT_SILVER_BUCKET: "{{ vars.dbt_silver_bucket }}"
      DBT_ICEBERG_BASE_PATH: "{{ vars.dbt_iceberg_base_path }}"
      EXECUTION_DATE: "{{ inputs.execution_date }}"
      PIPELINE_MODE: "{{ vars.run_mode }}"
      # Iceberg metadata locations from DynamoDB (keeping as fallback)
      FRANKFURTER_METADATA_LOCATION: "{{ outputs.fetch_iceberg_metadata_paths.outputs.frankfurter_metadata | default('') }}"
      EXCHANGERATE_METADATA_LOCATION: "{{ outputs.fetch_iceberg_metadata_paths.outputs.exchangerate_metadata | default('') }}"
      CURRENCYLAYER_METADATA_LOCATION: "{{ outputs.fetch_iceberg_metadata_paths.outputs.currencylayer_metadata | default('') }}"
    commands:
      - dbt deps
      - dbt build
      - pwd
      - ls -lah .
      - find . -name "*.duckdb" -o -name "*.db"

  - id: upload_ddb_file
    type: io.kestra.plugin.minio.Upload
    namespaceFiles:
      enabled: true
    region: "{{ envs.dynamodb_aws_default_region }}"
    endpoint: "{{ envs.minio_endpoint }}"  
    accessKeyId: "{{ envs.destination__filesystem__credentials__aws_access_key_id }}"
    secretKeyId: "{{ envs.destination__filesystem__credentials__aws_secret_access_key }}"
    from: "{{ outputs.dbt_validation_and_transform.outputFiles['analytics.duckdb'] }}" #"{{ outputs.dbt_validation_and_transform.outputFiles['analytics.duckdb'] }}"
    bucket: "analytics-bucket"
    key: "analytics.duckdb"
         


  # ===== 4. UPSERT TO DYNAMODB =====
  - id: sync_to_dynamodb
    type: io.kestra.plugin.docker.Run
    namespaceFiles:
      enabled: true
    dependsOn:
      - dbt_validation_and_transform
    containerImage: makerates-ingestion-base:latest
    pullPolicy: NEVER
    networkMode: makerates-network
    inputFiles:
      analytics.duckdb: "{{ outputs.dbt_validation_and_transform.outputFiles['analytics.duckdb'] }}"
    env:
      AWS_ACCESS_KEY_ID: "{{ vars.dlt_aws_access_key_id }}"
      AWS_SECRET_ACCESS_KEY: "{{ vars.dlt_aws_secret_access_key }}"
      AWS_ENDPOINT_URL: "{{ vars.minio_endpoint }}"
      AWS_REGION: "{{ vars.ddb_default_region }}"
      DYNAMODB_TABLE_NAME: "{{ vars.dynamodb_currencies_table_name }}"
      DYNAMODB_ENDPOINT_URL: "{{ vars.dynamodb_endpoint }}"
      DYNAMODB_REGION: "{{ vars.ddb_default_region }}"
      DUCKDB_PATH: "analytics.duckdb" # Reads from Kestra inputFiles
      MODE: "{{ vars.run_mode }}"
    workingDir: /app
    commands:
      - sync_gold_to_dynamodb # Uses python -m entrypoint, PYTHONPATH=/app/src
      # - sync_gold_to_dynamodb
    timeout: PT5M
    retry:
      type: constant
      interval: PT30S
      maxAttempt: 3


triggers:
  - id: daily_schedule
    type: io.kestra.core.models.triggers.types.Schedule
    cron: "0 6 * * *"
    description: Daily at 6 AM UTC
    inputs:
      execution_date: "{{ trigger.date | date('yyyy-MM-dd') }}"

errors:
  - id: backfill_error
    type: io.kestra.plugin.core.log.Log
    message: I'm failing {{ errorLogs()[0]['taskId'] }} 
    level: ERROR
